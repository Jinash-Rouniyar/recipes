{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction - RAG Chatbot with Semantic Kernel\n",
    "\n",
    "### Implements a simple workflow of retrieve then generate. using `semantic kernel` to help with prompt engineering and orchestrating OpenAI API calls and Weaviate as knowledgebase from which to retreive semantically relevant context. This allows us to not only control what is being generated but also cite sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 0.18.230725.3-preview\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Memory.Weaviate, 0.18.230725.3-preview\"\n",
    "\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.Memory.Weaviate;\n",
    "using Microsoft.SemanticKernel.Memory;\n",
    "using Microsoft.SemanticKernel.Skills.Core;\n",
    "using Microsoft.SemanticKernel.SkillDefinition;\n",
    "using Microsoft.SemanticKernel.Orchestration;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OS-specific notes:\n",
    "* if you run into SSL errors when connecting to OpenAI on macOS, see this issue for a [potential solution](https://github.com/microsoft/semantic-kernel/issues/627#issuecomment-1580912248)\n",
    "* on Windows, you may need to run Docker Desktop as administrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var apiKey = \"my-secret-key\";\n",
    "WeaviateMemoryStore memoryStore = new(\"http://localhost:8080/v1/\", apiKey);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we register the memory store to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var openApiKey = \"\";\n",
    "IKernel kernel = Microsoft.SemanticKernel.Kernel.Builder\n",
    "                       .WithOpenAITextCompletionService(\"text-davinci-003\", openApiKey)\n",
    "                       .WithOpenAITextEmbeddingGenerationService(\"text-embedding-ada-002\", openApiKey)\n",
    "                       .WithMemoryStorage(memoryStore)\n",
    "                       .Build();\n",
    "kernel.ImportSkill(new TextMemorySkill(kernel.Memory));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually adding memories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some initial memories \"About Me\". We can add memories to our weaviate memory store by using `save_information_async`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string collectionName = \"AboutMe\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Function for persisting a memory to Weaviate\n",
    "\n",
    "async Task Remember(string memory, string collection, IKernel kernel)\n",
    "{\n",
    "    // Add some documents to the semantic memory\n",
    "    await kernel.Memory.SaveInformationAsync(collection, memory, Guid.NewGuid().ToString());\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "await Remember(\"When I turned 5 my parents gifted me goldfish for my birthday\", collectionName,  kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "await Remember(\"I love datascience\", collectionName, kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "await Remember(\"I have a black nissan sentra\", collectionName, kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "await Remember(\"my favourite food is popcorn\", collectionName, kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "await Remember(\"I like to take long walks.\", collectionName, kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var result = kernel.Memory.SearchAsync(collectionName, \"Do I have a pet?\", limit: 1);\n",
    "await foreach (var item in result)\n",
    "{\n",
    "    Console.WriteLine(item.Metadata.Text);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var result2 = kernel.Memory.SearchAsync(collectionName, \"passion\", limit: 3);\n",
    "await foreach (var item in result2)\n",
    "{\n",
    "    Console.WriteLine(item.Metadata.Text);\n",
    "    Console.WriteLine(item.Relevance);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "async Task<Tuple<ISKFunction, SKContext>> SetupRAG(IKernel kernel)\n",
    "{\n",
    "    var prompt = @\"\"\"\n",
    "            You are a friendly and talkative AI.\n",
    "            Answer to the user question: {{$user_input}}\n",
    "            You can, but don't have to, use relevant information provided here: {{$retreived_context}} \n",
    "            If you are not sure of the answer say \"\"I am not sure.\"\"\n",
    "            \"\"\".Trim();\n",
    "    var func = kernel.CreateSemanticFunction(prompt);\n",
    "    var context = kernel.CreateNewContext();\n",
    "    context[\"chat_history\"] = \"\";\n",
    "    context[\"retreived_context\"] = \"\";\n",
    "    return Tuple.Create(func, context);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.DotNet.Interactive;\n",
    "\n",
    "async Task<bool> RAG(IKernel kernel, ISKFunction ragFunc, SKContext context)\n",
    "{\n",
    "    var userInput = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Enter text:\");\n",
    "\n",
    "    context[\"user_input\"] = userInput;\n",
    "\n",
    "    if (userInput == \"exit\") {\n",
    "        Console.WriteLine(\"Exiting chat...\");\n",
    "        return false;\n",
    "    }\n",
    "\n",
    "    var result = kernel.Memory.SearchAsync(collectionName, userInput, limit: 5, minRelevanceScore: 0.5);\n",
    "    var retrieved = new List<string>();\n",
    "    await foreach (var item in result)\n",
    "    {\n",
    "        retrieved.Add(item.Metadata.Text);\n",
    "    }\n",
    "    context[\"retreived_context\"] = string.Join(\". \", retrieved).Trim();\n",
    "\n",
    "    var answer = await ragFunc.InvokeAsync(context);\n",
    "\n",
    "    // TODO: Insert the response back into Weaviate using remember()\n",
    "    // Chat history is kind of bad, we might just want to retrieve 2-3 memories from Weaviate and use them so that \n",
    "    // input length doesn't grow as we keep chatting.\n",
    "\n",
    "    context[\"chat_history\"] += $\"\\nUser:> {userInput}\\nChatBot:> {answer}\\n\";\n",
    "    Console.WriteLine($\"{answer}\");\n",
    "\n",
    "    return true;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "Console.WriteLine(\"Setting up a chat (with memory!)\");\n",
    "var (rag_func, context) = await SetupRAG(kernel);\n",
    "\n",
    "Console.WriteLine(\"Begin chatting (type 'exit' to exit):\\n\");\n",
    "var chatting = true;\n",
    "while (chatting)\n",
    "     chatting = await RAG(kernel, rag_func, context);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// The chathistory can be obtained from the context.\n",
    "Console.WriteLine(context.Variables[\"chat_history\"]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
