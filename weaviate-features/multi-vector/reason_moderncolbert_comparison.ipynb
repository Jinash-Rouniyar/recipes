{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Agentic RAG vs Reason-ModernColBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook author: Danny Williams @ Weaviate\n",
    "\n",
    "This notebook will compare an 'agentic' RAG solution to dynamically searching a database via breaking down a question with complex reasoning, to a new method for complex reasoning retrieval: [Reason-ModernColBERT](https://huggingface.co/lightonai/Reason-ModernColBERT).\n",
    "\n",
    "For an overview of Reason-ModernColBERT, I recommend you check out [this recipe](https://github.com/weaviate/recipes/blob/main/weaviate-features/multi-vector/reason_moderncolbert.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, let's set up the dependencies for the notebook. For our generative models we will use OpenAI (and tiktoken for counting tokens), we need PyLate and Sentence Transformers to load the Reason-ModernColBERT model, we will of course use Weaviate as the vector database search engine, and to assess the quality of the results we will use DeepEval. We will also use rich for pretty printing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install weaviate-client==4.15.0\n",
    "!pip install pylate==1.2.0\n",
    "!pip install openai==1.84.0\n",
    "!pip install tiktoken==0.9.0\n",
    "!pip install deepeval==3.0.1\n",
    "!pip install rich==13.9.4\n",
    "!pip install protobuf==6.31.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional requirements include your Weaviate instance being on version 1.29 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also suppress some warnings to make the notebook cleaner\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define some helper functions for later which count and reduce the number of tokens in the data so we can truncate the texts if they are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def tokenize_text(text: str):\n",
    "    return tiktoken.get_encoding(\"o200k_base\").encode(text)\n",
    "\n",
    "def reduce_tokens(text: str, max_tokens: int):\n",
    "    tokens = tokenize_text(text)\n",
    "    if len(tokens) > max_tokens:\n",
    "        return tiktoken.get_encoding(\"o200k_base\").decode(tokens[:max_tokens])\n",
    "    return text\n",
    "\n",
    "def count_tokens(text: str):\n",
    "    return len(tokenize_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define the embedding function for the target multi vector, using the Reason-ModernColBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylate import models\n",
    "\n",
    "# Load the ModernColBERT model\n",
    "model = models.ColBERT(\n",
    "    model_name_or_path=\"lightonai/Reason-ModernColBERT\",\n",
    ")\n",
    "\n",
    "def multi_vec_embed(text: str):\n",
    "    return model.encode(text, is_query=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the [BioASQ dataset](https://www.bioasq.org/), as it contains a lot of domain specific knowledge, whose questions require breaking down into individual parts and complex reasoning to obtain good retrieval performance. The BioASQ dataset contains:\n",
    "- 40.2K text passages\n",
    "- 4.72K question and answer pairs with corresponding relevant passage ids\n",
    "\n",
    "For this example notebook, let us consider only a subset of 100 questions. Each question has corresponding `relevant_passage_ids`, which is a list detailing which passages are pertinent to answering the question. We will include all these relevant passage IDs in the subset dataset, as well as a sample of irrelevant passages.\n",
    "\n",
    "Let us first use pandas to load these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "questions_splits = {'train': 'question-answer-passages/train-00000-of-00001.parquet', 'test': 'question-answer-passages/test-00000-of-00001.parquet'}\n",
    "questions_df = pd.read_parquet(\"hf://datasets/enelpol/rag-mini-bioasq/\" + questions_splits[\"train\"])\n",
    "\n",
    "texts_splits = {'train': 'text-corpus/train-00000-of-00001.parquet', 'test': 'text-corpus/test-00000-of-00001.parquet'}\n",
    "texts_df = pd.read_parquet(\"hf://datasets/enelpol/rag-mini-bioasq/\" + texts_splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at a brief snapshot of the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>relevant_passage_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the implication of histone lysine meth...</td>\n",
       "      <td>Aberrant patterns of H3K4, H3K9, and H3K27 his...</td>\n",
       "      <td>1682</td>\n",
       "      <td>[23179372, 19270706, 23184418]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of STAG1/STAG2 proteins in di...</td>\n",
       "      <td>STAG1/STAG2 proteins are tumour suppressor pro...</td>\n",
       "      <td>3722</td>\n",
       "      <td>[26997282, 21589869, 19822671, 29867216, 15361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the association between cell phone use...</td>\n",
       "      <td>The association between cell phone use and inc...</td>\n",
       "      <td>1235</td>\n",
       "      <td>[20215713, 17851009, 22882019, 12527940, 24348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the applicability of the No Promoter L...</td>\n",
       "      <td>No Promoter Left Behind (NPLB) is an efficient...</td>\n",
       "      <td>2103</td>\n",
       "      <td>[26530723]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does the Oncotype DX test work with paraffin e...</td>\n",
       "      <td>Yes, the Oncotype DX test works with paraffin ...</td>\n",
       "      <td>1713</td>\n",
       "      <td>[23074401, 17039265, 18922117, 17463177, 16361...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the implication of histone lysine meth...   \n",
       "1  What is the role of STAG1/STAG2 proteins in di...   \n",
       "2  What is the association between cell phone use...   \n",
       "3  What is the applicability of the No Promoter L...   \n",
       "4  Does the Oncotype DX test work with paraffin e...   \n",
       "\n",
       "                                              answer    id  \\\n",
       "0  Aberrant patterns of H3K4, H3K9, and H3K27 his...  1682   \n",
       "1  STAG1/STAG2 proteins are tumour suppressor pro...  3722   \n",
       "2  The association between cell phone use and inc...  1235   \n",
       "3  No Promoter Left Behind (NPLB) is an efficient...  2103   \n",
       "4  Yes, the Oncotype DX test works with paraffin ...  1713   \n",
       "\n",
       "                                relevant_passage_ids  \n",
       "0                     [23179372, 19270706, 23184418]  \n",
       "1  [26997282, 21589869, 19822671, 29867216, 15361...  \n",
       "2  [20215713, 17851009, 22882019, 12527940, 24348...  \n",
       "3                                         [26530723]  \n",
       "4  [23074401, 17039265, 18922117, 17463177, 16361...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New data on viruses isolated from patients wit...</td>\n",
       "      <td>9797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We describe an improved method for detecting d...</td>\n",
       "      <td>11906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We have studied the effects of curare on respo...</td>\n",
       "      <td>16083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kinetic and electrophoretic properties of 230-...</td>\n",
       "      <td>23188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male Wistar specific-pathogen-free rats aged 2...</td>\n",
       "      <td>23469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             passage     id\n",
       "0  New data on viruses isolated from patients wit...   9797\n",
       "1  We describe an improved method for detecting d...  11906\n",
       "2  We have studied the effects of curare on respo...  16083\n",
       "3  Kinetic and electrophoretic properties of 230-...  23188\n",
       "4  Male Wistar specific-pathogen-free rats aged 2...  23469"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_questions_df = questions_df.sample(frac=100/len(questions_df))\n",
    "\n",
    "relevant_passages = []\n",
    "for i, row in subset_questions_df.iterrows():\n",
    "    relevant_passages.extend(row[\"relevant_passage_ids\"])\n",
    "\n",
    "relevant_passages = list(set(relevant_passages))\n",
    "irrelevant_passages = texts_df.id.tolist()\n",
    "irrelevant_passages = [p for p in irrelevant_passages if p not in relevant_passages]\n",
    "\n",
    "# Get twice as many irrelevant passages\n",
    "import random\n",
    "random.seed(42)\n",
    "irrelevant_passages = random.sample(irrelevant_passages, len(relevant_passages)*2)\n",
    "\n",
    "subset_texts_df = texts_df[texts_df.id.isin(relevant_passages + irrelevant_passages)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant passages: 722\n",
      "Number of irrelevant passages: 1444\n",
      "Subset of 2166 passages created\n",
      "Subset of 100 questions created\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of relevant passages: {len(relevant_passages)}\")\n",
    "print(f\"Number of irrelevant passages: {len(irrelevant_passages)}\")\n",
    "print(f\"Subset of {len(subset_texts_df)} passages created\")\n",
    "print(f\"Subset of {len(subset_questions_df)} questions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data to Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's connect to the Weaviate client. In this instance we are connecting to Weaviate cloud using API keys stored in the local environment. But you can also use [Weaviate Embedded](https://weaviate.io/developers/weaviate/installation/embedded), [Docker](https://weaviate.io/developers/weaviate/installation/docker-compose), amongst other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=os.getenv(\"WCD_URL\"),\n",
    "    auth_credentials=Auth.api_key(os.getenv(\"WCD_API_KEY\")),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a collection called `bioASQ_data`, containing two named vectors - one for the single vector embeddings (using the default OpenAI vectorizer), and one with the multi-vector embeddings using the Reason-ModernColBERT model. For both we will use [scalar quantization](https://weaviate.io/developers/weaviate/concepts/vector-quantization#scalar-quantization) to reduce the memory footprint of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danny/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/collections/classes/config.py:1975: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  for cls_field in self.model_fields:\n"
     ]
    },
    {
     "ename": "UnexpectedStatusCodeError",
     "evalue": "Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'class name BioASQ_passages already exists'}]}.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m collection = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbioASQ_passages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectorizer_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNamedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmulti_vector\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvector_index_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectorIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhnsw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmulti_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectorIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMultiVector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectorIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMultiVector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEncoding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmuvera\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNamedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext2vec_openai\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msingle_vector\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvector_index_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectorIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhnsw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mProperty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDataType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTEXT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvectorize_property_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mProperty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDataType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTEXT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvectorize_property_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/collections/collections/executor.py:231\u001b[39m, in \u001b[36m_CollectionsExecutor.create\u001b[39m\u001b[34m(self, name, description, generative_config, inverted_index_config, multi_tenancy_config, properties, references, replication_config, reranker_config, sharding_config, vector_index_config, vectorizer_config, data_model_properties, data_model_references, skip_argument_validation)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateInvalidInputError(\n\u001b[32m    228\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid collection config create parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    229\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_model_properties\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_model_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_model_references\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_model_references\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_argument_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_argument_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/collections/collections/executor.py:102\u001b[39m, in \u001b[36m_CollectionsExecutor.__create\u001b[39m\u001b[34m(self, config, data_model_properties, data_model_references, skip_argument_validation)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__create\u001b[39m(\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     93\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m     Awaitable[CollectionAsync[Properties, References]],\n\u001b[32m    101\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/schema\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCollection may not have been created properly.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ExpectedStatusCodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mok_in\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCreate collection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Awaitable):\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:822\u001b[39m, in \u001b[36m_ConnectionBase.post\u001b[39m\u001b[34m(self, path, weaviate_object, params, error_msg, status_codes, is_gql_query)\u001b[39m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m    814\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    815\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m     is_gql_query: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    821\u001b[39m ) -> executor.Result[Response]:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_version_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweaviate_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_gql_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_gql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:716\u001b[39m, in \u001b[36m_ConnectionBase._send\u001b[39m\u001b[34m(self, method, url, error_msg, status_codes, is_gql_query, weaviate_object, params, check_is_connected)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexc\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    714\u001b[39m     \u001b[38;5;28mself\u001b[39m.__handle_exceptions(e, error_msg)\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexception_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/executor.py:99\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, \u001b[43mexception_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:714\u001b[39m, in \u001b[36m_ConnectionBase._send.<locals>.exc\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexc\u001b[39m(e: \u001b[38;5;167;01mException\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m714\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__handle_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:670\u001b[39m, in \u001b[36m_ConnectionBase.__handle_exceptions\u001b[39m\u001b[34m(self, e, error_msg)\u001b[39m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeout):\n\u001b[32m    669\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WeaviateTimeoutError(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/executor.py:95\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(method, response_callback, exception_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cast(T, exception_callback(e))\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _execute()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m resp_call = \u001b[43mresponse_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp_call, Awaitable)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp_call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:711\u001b[39m, in \u001b[36m_ConnectionBase._send.<locals>.resp\u001b[39m\u001b[34m(res)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresp\u001b[39m(res: Response) -> Response:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__handle_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus_codes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/weaviate/connect/v4.py:681\u001b[39m, in \u001b[36m_ConnectionBase.__handle_response\u001b[39m\u001b[34m(self, response, error_msg, status_codes)\u001b[39m\n\u001b[32m    679\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InsufficientPermissionsError(response)\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m status_codes.ok:\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedStatusCodeError(error_msg, response)\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mUnexpectedStatusCodeError\u001b[39m: Collection may not have been created properly.! Unexpected status code: 422, with response body: {'error': [{'message': 'class name BioASQ_passages already exists'}]}."
     ]
    }
   ],
   "source": [
    "collection = client.collections.create(\n",
    "    \"bioASQ_data\",\n",
    "    vectorizer_config=[\n",
    "        Configure.NamedVectors.none(\n",
    "            name=\"multi_vector\",\n",
    "            vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                multi_vector=Configure.VectorIndex.MultiVector.multi_vector(\n",
    "                    encoding=Configure.VectorIndex.MultiVector.Encoding.muvera()\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        Configure.NamedVectors.text2vec_openai(\n",
    "            name=\"single_vector\",\n",
    "            vector_index_config=Configure.VectorIndex.hnsw()\n",
    "        ),  \n",
    "    ],\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"text\",\n",
    "            data_type=DataType.TEXT,\n",
    "            vectorize_property_name=False  \n",
    "        ),\n",
    "        Property(\n",
    "            name=\"docid\",\n",
    "            data_type=DataType.TEXT,\n",
    "            vectorize_property_name=False  \n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import to Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/2499"
     ]
    }
   ],
   "source": [
    "from weaviate.util import generate_uuid5\n",
    "collection = client.collections.get(\"bioASQ_data\")\n",
    "with collection.batch.fixed_size(10) as batch:\n",
    "    for iter, (_, doc) in enumerate(subset_texts_df.iterrows()):\n",
    "\n",
    "        uuid = generate_uuid5(doc.id)\n",
    "\n",
    "        text = doc.passage\n",
    "        \n",
    "        if count_tokens(text) > 6_000:\n",
    "            text = reduce_tokens(text, 6_000) # truncate long documents\n",
    "\n",
    "        batch.add_object(\n",
    "            properties={\"text\": text, \"docid\": str(doc.id)},\n",
    "            vector={\"multi_vector\": multi_vec_embed(text)},\n",
    "            uuid=uuid\n",
    "        )\n",
    "\n",
    "        print(f\"\\r{iter+1}/{len(subset_texts_df)}\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "answer_question_system_prompt = \"\"\"\n",
    "You are an expert at answering biomedical questions using a given context.\n",
    "You will be given a question, and a list of documents.\n",
    "You need to answer the question using the context.\n",
    "Do not answer the question if you do not have enough information.\n",
    "If the context does not fully answer the question, you must respond with \"I do not know\" or similar.\n",
    "Provide the answer only in a concise manner.\n",
    "Use citations to reference the context in your answer. It should be formatted as e.g. \"[1]\" at the end of each sentence that references the context.\n",
    "The contexts are marked with a number in square brackets, e.g. \"[1]\", at the beginning of each context.\n",
    "\"\"\"\n",
    "\n",
    "class AnswerQuestionOutput(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "def answer_question(question: str, context: list[str]):\n",
    "    context_str = \"\"\n",
    "    for i, c in enumerate(context):\n",
    "        context_str += f\"[{i+1}]: {c}\\n\\n\"\n",
    "\n",
    "    response = openai_client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": answer_question_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\\nContext: {context_str}\"}\n",
    "        ],\n",
    "        response_format=AnswerQuestionOutput\n",
    "    )\n",
    "    return response.choices[0].message.parsed.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agentic RAG with Single Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Agentic' RAG pipeline we will build is as follows. First, the system prompt loosely defines the dataset and gives instructions to the model to break down the question in terms of its core components. Then the model will extract these components to use in a search engine (Weaviate).\n",
    "\n",
    "The reasoning field will improve the model performance via chain-of-thought prompting, and allow the model to decide what parts of the question need to be delved into deeper to get more relevant search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danny/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/pydantic/fields.py:1058: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  warn('`min_items` is deprecated and will be removed, use `min_length` instead', DeprecationWarning)\n",
      "/Users/danny/Documents/Work/Other/recipes/.venv/lib/python3.12/site-packages/pydantic/fields.py:1064: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  warn('`max_items` is deprecated and will be removed, use `max_length` instead', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import numpy as np\n",
    "\n",
    "class ModelOutput(BaseModel):\n",
    "    reasoning: str\n",
    "    search_components: list[str] = Field(min_items=3, max_items=3) # ensure the model is forced to provide 3 components (for comparison equity)\n",
    "\n",
    "extract_reasoning_system_prompt = \"\"\"\n",
    "You are an expert at breaking down biomedical questions into their fundamental components used for a retrieval service.\n",
    "You will be given a question, and you need to first explain your reasoning for breaking down the question into the components.\n",
    "Then you need to provide the components.\n",
    "Think carefully about what these components should be - it may not be outright stated in the question.\n",
    "Use deductive reasoning to think step by step to complete this task.\n",
    "Each component should be independent as they will be used separately to find relevant documents via a search engine.\n",
    "You MUST provide 3 components only. No more, no less.\n",
    "\"\"\"\n",
    "\n",
    "# Use GPT-4.1-mini for the model (cheaper option but will have lower quality)\n",
    "def extract_reasoning(question: str):\n",
    "    response = openai_client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": extract_reasoning_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "        ],\n",
    "        response_format=ModelOutput\n",
    "    )\n",
    "    reasoning = response.choices[0].message.parsed.reasoning\n",
    "    components = response.choices[0].message.parsed.search_components\n",
    "    return reasoning, components\n",
    "\n",
    "def agentic_rag_search(question: str, verbose: bool = False):\n",
    "    reasoning, components = extract_reasoning(question)\n",
    "    if verbose:\n",
    "        print(f\"Model Reasoning:\\n{reasoning}\")\n",
    "    \n",
    "    contexts = []\n",
    "    doc_ids = []\n",
    "    distances = []\n",
    "    for search_component in components:\n",
    "\n",
    "        # search with weaviate vector search\n",
    "        response = collection.query.near_text(\n",
    "            query=search_component,\n",
    "            target_vector=\"single_vector\", # specify the single vector (not multi-vector)\n",
    "            return_metadata=weaviate.classes.query.MetadataQuery(\n",
    "                distance=True,\n",
    "            ),\n",
    "            limit=5\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Search Component: '{search_component}'\")\n",
    "            print(f\"Search Results:\")\n",
    "            for i,obj in enumerate(response.objects):\n",
    "                print(f\"  {i+1}. {obj.properties['text'][:50].replace('\\n', ' ')}... - Distance: {obj.metadata.distance}\")\n",
    "\n",
    "        # append the results\n",
    "        contexts.extend([f\"{obj.properties['text']} - Distance: {obj.metadata.distance}\" for obj in response.objects])\n",
    "        doc_ids.extend([int(obj.properties['docid']) for obj in response.objects])\n",
    "        distances.extend([obj.metadata.distance for obj in response.objects])\n",
    "\n",
    "    # order the contexts by distance\n",
    "    sort_order = np.argsort(distances)\n",
    "    contexts = [contexts[i] for i in sort_order]\n",
    "    doc_ids = [doc_ids[i] for i in sort_order]\n",
    "\n",
    "    answer = answer_question(question, contexts)\n",
    "    if verbose:\n",
    "        print(f\"Answer: {answer}\")\n",
    "    return answer, contexts, doc_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let's run the agentic model on the first question in the dataset to see an example in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Reasoning:\n",
      "The question asks about what the UV-damaged DNA-binding protein (UV-DDB) complex detects. To answer this, it is essential to identify the molecular target or lesion recognized by the UV-DDB complex during DNA repair. Since the question involves a specific protein complex and its function in DNA damage recognition, the components should focus on: (1) the UV-DDB protein complex itself, (2) the type of DNA damage it detects, and (3) the biological process or context, which is DNA repair, specifically nucleotide excision repair.\n",
      "Search Component: 'UV-damaged DNA-binding protein (UV-DDB) complex'\n",
      "Search Results:\n",
      "  1. The UV-damaged DNA binding protein complex (UV-DDB... - Distance: 0.27205049991607666\n",
      "  2. Xeroderma pigmentosum (XP) is a heritable human di... - Distance: 0.40062063932418823\n",
      "  3. Xeroderma pigmentosum (XP) is a skin cancer-prone ... - Distance: 0.4280959963798523\n",
      "  4. Repair of covalent DNA-protein crosslinks (DPCs) b... - Distance: 0.4421839714050293\n",
      "  5. Covalent DNA-protein crosslinks (DPCs) have emerge... - Distance: 0.44599199295043945\n",
      "Search Component: 'DNA damage recognized by UV-DDB'\n",
      "Search Results:\n",
      "  1. The UV-damaged DNA binding protein complex (UV-DDB... - Distance: 0.34093916416168213\n",
      "  2. Xeroderma pigmentosum (XP) is a heritable human di... - Distance: 0.4353083372116089\n",
      "  3. Exposure to solar radiation can cause mortality in... - Distance: 0.4561508893966675\n",
      "  4. Xeroderma pigmentosum (XP) is a skin cancer-prone ... - Distance: 0.46503007411956787\n",
      "  5. Covalent DNA-protein crosslinks (DPCs) have emerge... - Distance: 0.46832597255706787\n",
      "Search Component: 'DNA repair mechanisms involving UV-DDB'\n",
      "Search Results:\n",
      "  1. The UV-damaged DNA binding protein complex (UV-DDB... - Distance: 0.33285093307495117\n",
      "  2. Xeroderma pigmentosum (XP) is a heritable human di... - Distance: 0.4236806631088257\n",
      "  3. Xeroderma pigmentosum (XP) is a skin cancer-prone ... - Distance: 0.4462391138076782\n",
      "  4. Repair of covalent DNA-protein crosslinks (DPCs) b... - Distance: 0.4486088156700134\n",
      "  5. Exposure to solar radiation can cause mortality in... - Distance: 0.45558691024780273\n",
      "Answer: The UV-damaged DNA-binding protein (UV-DDB) complex detects UV-damaged DNA, specifically binding to photolesions caused by UV irradiation, and is implicated in the damage recognition step of global genomic nucleotide excision repair (NER) in mammalian cells. It binds to UV-induced DNA lesions, facilitating repair in non-transcribed regions of the genome. The complex consists of two subunits, p127 and p48 (DDB1 and DDB2), and defects in this complex are linked to the xeroderma pigmentosum group E (XP-E) disorder which is characterized by impaired recognition of UV-damaged DNA [1,4,6].\n"
     ]
    }
   ],
   "source": [
    "agentic_rag_search(subset_questions_df.iloc[0][\"question\"], verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason Modern-ColBERT Embedding Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reason_moderncolbert_search(question: str, verbose: bool = False):\n",
    "\n",
    "    # search with weaviate near vector search (using custom multi-vector)\n",
    "    response = collection.query.near_vector(\n",
    "        near_vector=multi_vec_embed(question),\n",
    "        target_vector=\"multi_vector\", # specify the multi-vector (not single-vector)\n",
    "        return_metadata=weaviate.classes.query.MetadataQuery(\n",
    "            distance=True,\n",
    "        ),\n",
    "        limit=15 # 3*the results per component (which is max 3, so this search has the same number of contexts as agentic search)\n",
    "    )\n",
    "    distances = [obj.metadata.distance for obj in response.objects]\n",
    "    contexts = [f\"{obj.properties['text']} - Distance: {obj.metadata.distance}\" for obj in response.objects]\n",
    "    doc_ids = [int(obj.properties['docid']) for obj in response.objects]\n",
    "\n",
    "    # order the contexts by distance\n",
    "    sort_order = np.argsort(distances)\n",
    "    contexts = [contexts[i] for i in sort_order]\n",
    "    doc_ids = [doc_ids[i] for i in sort_order]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Search Results:\")\n",
    "        for i, context in enumerate(contexts):\n",
    "            print(f\"  {i+1}. {context[:25].replace('\\n', ' ')}... - Distance: {distances[i]}\")\n",
    "\n",
    "    # use the same answer_question function as the agentic search\n",
    "    answer = answer_question(question, contexts)\n",
    "    if verbose:\n",
    "        print(f\"Answer: {answer}\")\n",
    "    return answer, contexts, doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "  1. The UV-damaged DNA bindin... - Distance: -14.943934440612793\n",
      "  2. Xeroderma pigmentosum (XP... - Distance: -14.854622840881348\n",
      "  3. Xeroderma pigmentosum (XP... - Distance: -14.62043571472168\n",
      "  4. Transcription is coupled ... - Distance: -12.708366394042969\n",
      "  5. Fanconi anemia (FA) is a ... - Distance: -12.512289047241211\n",
      "  6. The COP9 signalosome (CSN... - Distance: -12.280506134033203\n",
      "  7. Several basic proteins, i... - Distance: -12.253641128540039\n",
      "  8. Accumulation of gadd153 m... - Distance: -12.232525825500488\n",
      "  9. Covalent DNA-protein cros... - Distance: -12.205463409423828\n",
      "  10. The Tousled-like kinases ... - Distance: -12.17816162109375\n",
      "  11. In higher eukaryotes, the... - Distance: -12.07862377166748\n",
      "  12. Genomic deoxyribonucleic ... - Distance: -12.059859275817871\n",
      "  13. Nucleotide excision repai... - Distance: -11.953145980834961\n",
      "  14. BACKGROUND: The colon and... - Distance: -11.925871849060059\n",
      "  15. Repair of covalent DNA-pr... - Distance: -11.924324989318848\n",
      "Answer: The UV-damaged DNA-binding protein (UV-DDB) complex detects UV-induced DNA damage, specifically binding to UV-damaged DNA such as photoproducts in the genome. It plays a crucial role in the global genomic nucleotide excision repair (NER) pathway by recognizing UV-induced lesions and facilitating their repair, particularly in the non-transcribed regions of the genome. UV-DDB is a heterodimer consisting of p127 and p48 subunits, which binds to UV-damaged DNA and is involved in the early steps of NER including chromatin remodeling and histone modification required for repair initiation [1][2][3].\n"
     ]
    }
   ],
   "source": [
    "reason_moderncolbert_search(subset_questions_df.iloc[0][\"question\"], verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure the *recall* of the retrieved passages, which measures how many correct passages were retrieved as a total of all the correct passages. The formula is:\n",
    "$$\n",
    "\\textrm{Recall} = \\frac{\n",
    "    \\textrm{True Positives}\n",
    "}{\n",
    "    \\textrm{True Positives} + \\textrm{False Negatives}\n",
    "}\n",
    "$$\n",
    "\n",
    "Note that recall can be increased simply by 'casting a wider net'. That is, increasing the number of passages you retrieve arbitrarily, as it does not get penalised based on the number of passages retrieved. So we can also measure precision:\n",
    "$$\n",
    "\\textrm{Precision} = \\frac{\n",
    "    \\textrm{True Positives}\n",
    "}{\n",
    "    \\textrm{True Positives} + \\textrm{False Positives}\n",
    "}\n",
    "$$\n",
    "Which will get penalised for the 'wider net' that we cast.\n",
    "\n",
    "Note that these scores are not strictly accurate or representative - we are fixing such that both methods return 15 results regardless of their scores/distances. However, it will still be a fair comparison between the two methods as they are both restricted in the same way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(relevant_passages: list[int], retrieved_passages: list[int]):\n",
    "    TP = set(relevant_passages).intersection(set(retrieved_passages))\n",
    "    return len(TP) / len(relevant_passages)  \n",
    "\n",
    "def precision(relevant_passages: list[int], retrieved_passages: list[int]):\n",
    "    TP = set(relevant_passages).intersection(set(retrieved_passages))\n",
    "    return len(TP) / len(retrieved_passages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [DeepEval framework](https://deepeval.com/) is a handy tool for measure certain statistics:\n",
    "- [Contextual Precision](https://deepeval.com/docs/metrics-contextual-precision) evaluates the relevance of the ranking of the retrieved contexts according to the question.\n",
    "- [Contextual Recall](https://deepeval.com/docs/metrics-contextual-recall) evaluates the quality of the retrieval context in how it aligns with the true answers.\n",
    "- [Answer Relevancy](https://deepeval.com/docs/metrics-answer-relevancy) evaluates the quality of the final answer output by the LLM.\n",
    "\n",
    "The DeepEval framework uses an LLM as a judge to determine these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import (\n",
    "    ContextualPrecisionMetric, ContextualRecallMetric, AnswerRelevancyMetric\n",
    ")\n",
    "\n",
    "llm_precision_metric = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    include_reason=False, # keep reasoning off for speed/compute cost\n",
    "    verbose_mode=False\n",
    ")\n",
    "\n",
    "llm_recall_metric = ContextualRecallMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    include_reason=False,\n",
    "    verbose_mode=False\n",
    ")\n",
    "\n",
    "llm_answer_relevancy_metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    include_reason=False,\n",
    "    verbose_mode=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the test cases for this subset of the question/answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists to store the test cases\n",
    "agentic_rag_test_cases = []\n",
    "reason_moderncolbert_test_cases = []\n",
    "\n",
    "# Set up dataframes to store the results\n",
    "recalls = pd.DataFrame(index=subset_questions_df.question, columns=[\"agentic_rag\", \"reason_moderncolbert\"])\n",
    "precisions = pd.DataFrame(index=subset_questions_df.question, columns=[\"agentic_rag\", \"reason_moderncolbert\"])\n",
    "\n",
    "# Iterate over the questions\n",
    "for i in range(len(subset_questions_df)):\n",
    "    question = subset_questions_df.iloc[i][\"question\"]\n",
    "    answer = subset_questions_df.iloc[i][\"answer\"]\n",
    "    relevant_passage_ids = subset_questions_df.iloc[i][\"relevant_passage_ids\"]\n",
    "\n",
    "    agentic_answer, agentic_contexts, agentic_doc_ids = agentic_rag_search(question)\n",
    "    reason_answer, reason_contexts, reason_doc_ids = reason_moderncolbert_search(question)\n",
    "\n",
    "    recalls.loc[question, \"agentic_rag\"] = recall(relevant_passage_ids, agentic_doc_ids)\n",
    "    recalls.loc[question, \"reason_moderncolbert\"] = recall(relevant_passage_ids, reason_doc_ids)\n",
    "\n",
    "    precisions.loc[question, \"agentic_rag\"] = precision(relevant_passage_ids, agentic_doc_ids)\n",
    "    precisions.loc[question, \"reason_moderncolbert\"] = precision(relevant_passage_ids, reason_doc_ids)\n",
    "\n",
    "    agentic_rag_test_case = LLMTestCase(\n",
    "        input=question, \n",
    "        actual_output=agentic_answer,\n",
    "        expected_output=answer,\n",
    "        retrieval_context=agentic_contexts\n",
    "    )\n",
    "\n",
    "    reason_moderncolbert_test_case = LLMTestCase(\n",
    "        input=question, \n",
    "        actual_output=reason_answer,\n",
    "        expected_output=answer,\n",
    "        retrieval_context=reason_contexts\n",
    "    )\n",
    "\n",
    "    agentic_rag_test_cases.append(agentic_rag_test_case)\n",
    "    reason_moderncolbert_test_cases.append(reason_moderncolbert_test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.evaluate import DisplayConfig\n",
    "eval_config = DisplayConfig(\n",
    "    verbose_mode=False,\n",
    "    print_results=False,\n",
    "    show_indicator=False\n",
    ")\n",
    "\n",
    "agentic_rag_results = evaluate(\n",
    "    test_cases=agentic_rag_test_cases, \n",
    "    metrics=[llm_precision_metric, llm_recall_metric, llm_answer_relevancy_metric],\n",
    "    display_config=eval_config\n",
    ")\n",
    "\n",
    "reason_moderncolbert_results = evaluate(\n",
    "    test_cases=reason_moderncolbert_test_cases, \n",
    "    metrics=[llm_precision_metric, llm_recall_metric, llm_answer_relevancy_metric],\n",
    "    display_config=eval_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's format the results before displaying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = pd.DataFrame(\n",
    "    columns=[\"agentic_rag\", \"reason_moderncolbert\"],\n",
    "    index=pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (question, metric)\n",
    "            for question in subset_questions_df.question\n",
    "            for metric in [\"Contextual Precision\", \"Contextual Recall\", \"Answer Relevancy\"]\n",
    "        ],\n",
    "        names=[\"question\", \"metric\"]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, test_result in enumerate(agentic_rag_results.test_results):\n",
    "    question = subset_questions_df.iloc[i][\"question\"]\n",
    "    for metrics_data in test_result.metrics_data:\n",
    "        metric = metrics_data.name\n",
    "        results_data.loc[(question, metric), \"agentic_rag\"] = metrics_data.score\n",
    "\n",
    "for i, test_result in enumerate(reason_moderncolbert_results.test_results):\n",
    "    question = subset_questions_df.iloc[i][\"question\"]\n",
    "    for metrics_data in test_result.metrics_data:\n",
    "        metric = metrics_data.name\n",
    "        results_data.loc[(question, metric), \"reason_moderncolbert\"] = metrics_data.score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can groupby the index on the `metric` index and see the average results for the DeepEval benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agentic_rag</th>\n",
       "      <th>reason_moderncolbert</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.941871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Precision</th>\n",
       "      <td>0.768626</td>\n",
       "      <td>0.894094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Recall</th>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.915714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     agentic_rag reason_moderncolbert\n",
       "metric                                               \n",
       "Answer Relevancy        0.917559             0.941871\n",
       "Contextual Precision    0.768626             0.894094\n",
       "Contextual Recall       0.864127             0.915714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data.groupby(level=[1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agentic_rag             0.666614\n",
       "reason_moderncolbert    0.884194\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agentic_rag                0.276\n",
       "reason_moderncolbert    0.420667\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisions.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
